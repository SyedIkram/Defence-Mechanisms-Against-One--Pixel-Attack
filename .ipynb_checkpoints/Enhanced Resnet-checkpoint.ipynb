{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from models.enhanced_resnet import EnhancedResnet\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch\n",
    "import cv2\n",
    "from scipy.optimize import differential_evolution\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from model import BasicCNN\n",
    "from torchvision.utils import save_image\n",
    "from models.enhanced_resnet import EnhancedResnet\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenoisingAutoEncoder(\n",
       "  (encoder1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ZeroPad2d(padding=(8, 8, 8, 8), value=0)\n",
       "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): ZeroPad2d(padding=(8, 8, 8, 8), value=0)\n",
       "  )\n",
       "  (encoder2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enm = EnhancedResnet()\n",
    "dnl = torch.load('./utils/logs/denoiser.pth')\n",
    "enm.denoised_layer.load_state_dict(dnl['model'])\n",
    "enm.denoised_layer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figs(imgs):\n",
    "    f = plt.figure(figsize=(8,4))\n",
    "    plt.axis('off')\n",
    "    tot = len(imgs)\n",
    "    i=0\n",
    "    pilTrans = transforms.ToPILImage()\n",
    "    for img in imgs:\n",
    "        i = i+1\n",
    "        f.add_subplot(1,tot, i)\n",
    "        plt.imshow(pilTrans(img))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = img.astype(np.float32)\n",
    "    img /= 255.0\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    return img\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "def scale(x, scale=5):\n",
    "    return cv2.resize(x, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(x):\n",
    "    adv_img = img.copy()\n",
    "    pixs = np.array(np.split(x, len(x)/5)).astype(int)\n",
    "    loc = (pixs[:, 0], pixs[:,1])\n",
    "    val = pixs[:, 2:]\n",
    "    adv_img[loc] = val\n",
    "    return adv_img\n",
    "def optimize(x):\n",
    "    adv_img = perturb(x)\n",
    "    inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    return prob[pred_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "tr = datasets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "pred_adv = 0\n",
    "prob_adv = 0\n",
    "def callback(x, convergence):\n",
    "    global pred_adv, prob_adv\n",
    "    adv_img = perturb(x)\n",
    "    inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    pred_adv = np.argmax(prob)\n",
    "    prob_adv = prob[pred_adv]\n",
    "    if pred_adv != pred_orig and prob_adv >= 0.9:\n",
    "        print('Attack successful..')\n",
    "        print('Prob [%s]: %f' %(cifar10_class_names[pred_adv], prob_adv))\n",
    "        print()\n",
    "        return True\n",
    "    else:\n",
    "        print('Prob [%s]: %f' %(cifar10_class_names[pred_orig], prob[pred_orig]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Image from the Dataset to attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 158\n",
    "fname = \"images/adv_img_\"+str(idx)+\".png\"\n",
    "d = 1\n",
    "iters = 600\n",
    "popsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnsr,lb = tr.__getitem__(idx)\n",
    "save_image(tnsr,\"images/testing.png\")\n",
    "image_path = \"images/testing.png\" #images/airplane.png(id-438) or car.png adv-3.png adv-37.png adv-158.png 221.png\n",
    "cifar10_class_names = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of the image before attack: dog\n"
     ]
    }
   ],
   "source": [
    "orig = cv2.imread(image_path)[..., ::-1]\n",
    "orig = cv2.resize(orig, (32, 32))\n",
    "img = orig.copy()\n",
    "shape = orig.shape\n",
    "model = BasicCNN()\n",
    "saved = torch.load(\"saved/cifar10_basiccnn.pth.tar\")\n",
    "model.load_state_dict(saved['state_dict'])\n",
    "model.eval()\n",
    "inp = Variable(torch.from_numpy(preprocess(img)).float().unsqueeze(0))\n",
    "prob_orig = softmax(model(inp).data.numpy()[0])\n",
    "pred_orig = np.argmax(prob_orig)\n",
    "print('Prediction of the image before attack: %s' %(cifar10_class_names[pred_orig]))\n",
    "#print('Probability: %f' %(prob_orig[pred_orig]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob [dog]: 0.082070\n",
      "Prob [dog]: 0.082070\n",
      "Prob [dog]: 0.082070\n",
      "Prob [dog]: 0.075346\n",
      "Prob [dog]: 0.066374\n",
      "Prob [dog]: 0.053754\n",
      "Prob [dog]: 0.047663\n",
      "Prob [dog]: 0.047663\n",
      "Prob [dog]: 0.033285\n",
      "Prob [dog]: 0.031849\n",
      "Prob [dog]: 0.031849\n",
      "Prob [dog]: 0.031849\n",
      "Prob [dog]: 0.031849\n",
      "Prob [dog]: 0.025812\n",
      "Prob [dog]: 0.025812\n",
      "Prob [dog]: 0.018565\n",
      "Prob [dog]: 0.018565\n",
      "Prob [dog]: 0.018565\n",
      "Prob [dog]: 0.018565\n",
      "Prob [dog]: 0.018565\n",
      "Prob [dog]: 0.018565\n",
      "Prob [dog]: 0.018565\n",
      "Prob [dog]: 0.017799\n",
      "Prob [dog]: 0.016698\n",
      "Prob [dog]: 0.016698\n",
      "Prob [dog]: 0.016698\n",
      "Prob [dog]: 0.016698\n",
      "Prob [dog]: 0.016698\n",
      "Prob [dog]: 0.016698\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016502\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.016433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:603: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence=self.tol / convergence) is True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob [dog]: 0.016433\n",
      "Prob [dog]: 0.339580 --> Prob[frog]: 0.816649\n"
     ]
    }
   ],
   "source": [
    "bounds = [(0, shape[0]-1), (0, shape[1]), (0, 255), (0, 255), (0, 255)] * d\n",
    "result = differential_evolution(optimize, bounds, maxiter=iters, popsize=popsize, tol=1e-5, callback=callback)\n",
    "adv_img = perturb(result.x)\n",
    "inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
    "out = model(inp)\n",
    "prob = softmax(out.data.numpy()[0])\n",
    "print('Prob [%s]: %f --> Prob[%s]: %f' %(cifar10_class_names[pred_orig], prob_orig[pred_orig], cifar10_class_names[pred_adv], prob_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(fname, adv_img[..., ::-1]) #images/adv_img_airplane.png\n",
    "cv2.imshow('adversarial image', scale(adv_img[..., ::-1]))\n",
    "while True:\n",
    "    key = cv2.waitKey(33)\n",
    "    if key == 27 or key == 32:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding autoencoding layers to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoised Image:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig = cv2.imread(fname)[..., ::-1] #images/adv_img_airplane.png or cat.png\n",
    "orig = preprocess(orig)\n",
    "inp = Variable(torch.from_numpy(orig)).float().unsqueeze(0)\n",
    "out = enm.denoised_layer(inp)\n",
    "z = torch.reshape(out,(3,32,32))\n",
    "print(\"Denoised Image:\")\n",
    "plot_figs([z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Variable(z).float().unsqueeze(0)\n",
    "out = model(inp)\n",
    "prob = softmax(out.data.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of the image before attack: dog\n",
      "With denoised layers, image is predicted as dog\n"
     ]
    }
   ],
   "source": [
    "n = cifar10_class_names[np.argmax(prob)]\n",
    "#v = np.amax(prob)\n",
    "print('Prediction of the image before attack: %s' %(cifar10_class_names[pred_orig]))\n",
    "#print('Probability: %f' %(prob_orig[pred_orig]))\n",
    "#if n==cifar10_class_names[pred_orig]:\n",
    "print('With denoised layers, image is predicted as %s'%(n))\n",
    "#else:\n",
    "#    v = prob[pred_orig]\n",
    "#    print('Confidence in original class is restored to: %f'%(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoStream:\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        self.stream.open('http://192.168.1.75:4747/video')\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while True:\n",
    "            if self.stopped:\n",
    "                return\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def read(self):\n",
    "        # Return the latest frame\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "score = 0\n",
    "pred = 0\n",
    "last = 0\n",
    "human_string = None\n",
    "vs = VideoStream(src=1).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "n = \"NONE\"\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame_count += 1\n",
    "    cv2.putText(frame, \"*\", (160, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (160, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    #frame = frame[40:160,40:160] #y1y2x1x2\n",
    "    if frame_count % 15 == 0:\n",
    "        img = frame[110:410,160:460] #y1y2x1x2\n",
    "        img = img[..., ::-1]\n",
    "        img = cv2.resize(img, (32, 32))\n",
    "        inp = Variable(torch.from_numpy(preprocess(img))).float().unsqueeze(0)\n",
    "        out = enm.denoised_layer(inp)\n",
    "        z = torch.reshape(out,(3,32,32))\n",
    "        inp = Variable(z).float().unsqueeze(0)\n",
    "        out = model(inp)\n",
    "        prob = softmax(out.data.numpy()[0])\n",
    "        n = cifar10_class_names[np.argmax(prob)]\n",
    "\n",
    "    cv2.putText(frame, n, (280, 400),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "   \n",
    "vs.stop()   \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before attack: airplane\n",
      "Probability: 0.544428\n",
      "With denoised layers, image is predicted as airplane with confidence 0.563950\n"
     ]
    }
   ],
   "source": [
    "n = cifar10_class_names[np.argmax(prob)]\n",
    "v = np.amax(prob)\n",
    "print('Prediction before attack: %s' %(cifar10_class_names[pred_orig]))\n",
    "print('Probability: %f' %(prob_orig[pred_orig]))\n",
    "if n==cifar10_class_names[pred_orig]:\n",
    "    print('With denoised layers, image is predicted as %s with confidence %f'%(n,v))\n",
    "else:\n",
    "    v = prob[pred_orig]\n",
    "    print('Confidence in original class is restored to: %f'%(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airplane'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36087736"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
