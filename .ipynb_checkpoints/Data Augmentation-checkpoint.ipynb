{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from models.enhanced_resnet import EnhancedResnet\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch\n",
    "import cv2\n",
    "from scipy.optimize import differential_evolution\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from model import BasicCNN\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import random\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figs(imgs):\n",
    "    f = plt.figure(figsize=(8,4))\n",
    "    plt.axis('off')\n",
    "    tot = len(imgs)\n",
    "    i=0\n",
    "    pilTrans = transforms.ToPILImage()\n",
    "    for img in imgs:\n",
    "        i = i+1\n",
    "        f.add_subplot(1,tot, i)\n",
    "        plt.imshow(pilTrans(img))\n",
    "    plt.show()\n",
    "def preprocess(img):\n",
    "    img = img.astype(np.float32)\n",
    "    img /= 255.0\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    return img\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "def scale(x, scale=5):\n",
    "    return cv2.resize(x, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "def perturb(x):\n",
    "    adv_img = img.copy()\n",
    "    pixs = np.array(np.split(x, len(x)/5)).astype(int)\n",
    "    loc = (pixs[:, 0], pixs[:,1])\n",
    "    val = pixs[:, 2:]\n",
    "    adv_img[loc] = val\n",
    "    return adv_img\n",
    "def optimize(x):\n",
    "    adv_img = perturb(x)\n",
    "    inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    return prob[pred_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "tr = datasets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "pred_adv = 0\n",
    "prob_adv = 0\n",
    "def callback(x, convergence):\n",
    "    global pred_adv, prob_adv\n",
    "    adv_img = perturb(x)\n",
    "    inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    pred_adv = np.argmax(prob)\n",
    "    prob_adv = prob[pred_adv]\n",
    "    if pred_adv != pred_orig and prob_adv >= 0.9:\n",
    "        print('Attack successful..')\n",
    "        print('Prob [%s]: %f' %(cifar10_class_names[pred_adv], prob_adv))\n",
    "        print()\n",
    "        return True\n",
    "    else:\n",
    "        print('Prob [%s]: %f' %(cifar10_class_names[pred_orig], prob[pred_orig]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 667\n",
    "fname = \"images/adv_img_\"+str(idx)+\".png\"\n",
    "d = 1\n",
    "iters = 600\n",
    "popsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnsr,lb = tr.__getitem__(idx)\n",
    "save_image(tnsr,\"images/testing.png\")\n",
    "image_path = \"images/testing.png\" #images/airplane.png or car.png adv-3.png adv-37.png adv-158.png 221.png\n",
    "cifar10_class_names = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before attack: airplane\n",
      "Probability: 0.997410\n"
     ]
    }
   ],
   "source": [
    "orig = cv2.imread(image_path)[..., ::-1]\n",
    "orig = cv2.resize(orig, (32, 32))\n",
    "img = orig.copy()\n",
    "shape = orig.shape\n",
    "model = BasicCNN()\n",
    "saved = torch.load(\"saved/cifar10_basiccnn.pth.tar\")\n",
    "model.load_state_dict(saved['state_dict'])\n",
    "model.eval()\n",
    "inp = Variable(torch.from_numpy(preprocess(img)).float().unsqueeze(0))\n",
    "prob_orig = softmax(model(inp).data.numpy()[0])\n",
    "pred_orig = np.argmax(prob_orig)\n",
    "print('Prediction before attack: %s' %(cifar10_class_names[pred_orig]))\n",
    "print('Probability: %f' %(prob_orig[pred_orig]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictimg(img):\n",
    "    tnsr = transforms.ToTensor()\n",
    "    i = random.randint(1,3)\n",
    "    if i==1:\n",
    "        print(\"Vertical transformation applied.\")\n",
    "        img = transforms.functional.vflip(img)\n",
    "    elif i==2:\n",
    "        print(\"Horizontal flip applied.\")\n",
    "        img = transforms.functional.hflip(img)\n",
    "    else:\n",
    "        ang = {1:30,2:45,3:60,4:120,5:135,6:225}\n",
    "        j = random.randint(1,6)\n",
    "        print(\"Imgae rotation with %d degrees applied.\"%(ang[j]))\n",
    "        img = transforms.functional.rotate(img,angle=ang[j]) \n",
    "    t = tnsr(img)\n",
    "    inp = Variable(t).float().unsqueeze(0)\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    n = cifar10_class_names[np.argmax(prob)]\n",
    "    v = np.amax(prob)\n",
    "    print('Prediction of the image after attack: %s' %(n))\n",
    "    print('Confidence: %f' %(v))\n",
    "    return n,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictimglive(img):\n",
    "    #tnsr = transforms.ToTensor()\n",
    "    i = random.randint(1,3)\n",
    "    if i==1:\n",
    "        print(\"Vertical Applied:\")\n",
    "        img = transforms.functional.vflip(img)\n",
    "    elif i==2:\n",
    "        print(\"Horizontal flip applied:\")\n",
    "        img = transforms.functional.hflip(img)\n",
    "    else:\n",
    "        ang = {1:30,2:45,3:60,4:120,5:135,6:225}\n",
    "        j = random.randint(1,6)\n",
    "        print(\"Imgae rotation with %d degrees applied:\"%(ang[j]))\n",
    "        img = transforms.functional.rotate(img,angle=ang[j]) \n",
    "    #t = tnsr(img)\n",
    "    inp = Variable(img).float().unsqueeze(0)\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    n = cifar10_class_names[np.argmax(prob)]\n",
    "    #v = np.amax(prob)\n",
    "    #print('Prediction of the image after attack: %s' %(n))\n",
    "    #print('Confidence: %f' %(v))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob [airplane]: 0.990263\n",
      "Prob [airplane]: 0.990263\n",
      "Prob [airplane]: 0.990263\n",
      "Prob [airplane]: 0.990263\n",
      "Prob [airplane]: 0.990263\n",
      "Prob [airplane]: 0.990263\n",
      "Prob [airplane]: 0.990263\n",
      "Prob [airplane]: 0.990263\n",
      "Prob [airplane]: 0.990125\n",
      "Prob [airplane]: 0.983787\n",
      "Prob [airplane]: 0.983787\n",
      "Prob [airplane]: 0.983787\n",
      "Prob [airplane]: 0.983787\n",
      "Prob [airplane]: 0.983787\n",
      "Prob [airplane]: 0.983787\n",
      "Prob [airplane]: 0.983787\n",
      "Prob [airplane]: 0.983787\n",
      "Prob [airplane]: 0.979997\n",
      "Prob [airplane]: 0.979997\n",
      "Prob [airplane]: 0.979997\n",
      "Prob [airplane]: 0.979705\n",
      "Prob [airplane]: 0.979705\n",
      "Prob [airplane]: 0.979705\n",
      "Prob [airplane]: 0.979705\n",
      "Prob [airplane]: 0.979705\n",
      "Prob [airplane]: 0.978727\n",
      "Prob [airplane]: 0.978727\n",
      "Prob [airplane]: 0.976638\n",
      "Prob [airplane]: 0.976566\n",
      "Prob [airplane]: 0.976566\n",
      "Prob [airplane]: 0.974624\n",
      "Prob [airplane]: 0.974624\n",
      "Prob [airplane]: 0.974549\n",
      "Prob [airplane]: 0.974171\n",
      "Prob [airplane]: 0.974171\n",
      "Prob [airplane]: 0.974171\n",
      "Prob [airplane]: 0.974171\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973884\n",
      "Prob [airplane]: 0.973882\n",
      "Prob [airplane]: 0.973882\n",
      "Prob [airplane]: 0.973882\n",
      "Prob [airplane]: 0.973882\n",
      "Prob [airplane]: 0.973882\n",
      "Prob [airplane]: 0.973882\n",
      "Prob [airplane]: 0.973882\n",
      "Prob [airplane]: 0.973882\n",
      "Prob [airplane]: 0.973882\n",
      "Prob [airplane]: 0.973876\n",
      "Prob [airplane]: 0.973876\n",
      "Prob [airplane]: 0.973876\n",
      "Prob [airplane]: 0.973876\n",
      "Prob [airplane]: 0.973876\n",
      "Prob [airplane]: 0.973876\n",
      "Prob [airplane]: 0.973876\n",
      "Prob [airplane]: 0.973876\n",
      "Prob [airplane]: 0.973876\n",
      "Prob [airplane]: 0.997410 --> Prob[airplane]: 0.973876\n"
     ]
    }
   ],
   "source": [
    "bounds = [(0, shape[0]-1), (0, shape[1]), (0, 255), (0, 255), (0, 255)] * d\n",
    "result = differential_evolution(optimize, bounds, maxiter=iters, popsize=popsize, tol=1e-5, callback=callback)\n",
    "adv_img = perturb(result.x)\n",
    "inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
    "out = model(inp)\n",
    "prob = softmax(out.data.numpy()[0])\n",
    "print('Prob [%s]: %f --> Prob[%s]: %f' %(cifar10_class_names[pred_orig], prob_orig[pred_orig], cifar10_class_names[pred_adv], prob_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(fname, adv_img[..., ::-1]) #images/adv_img_airplane.png\n",
    "cv2.imshow('adversarial image', scale(adv_img[..., ::-1]))\n",
    "while True:\n",
    "    key = cv2.waitKey(33)\n",
    "    if key == 27 or key == 32:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of adevrserial image with random data augmentation:\n",
      "Prediction before attack: airplane\n",
      "Probability: 0.997410\n",
      "Vertical transformation applied.\n",
      "Prediction of the image after attack: airplane\n",
      "Confidence: 0.999116\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction of adevrserial image with random data augmentation:\")\n",
    "print('Prediction before attack: %s' %(cifar10_class_names[pred_orig]))\n",
    "print('Probability: %f' %(prob_orig[pred_orig]))\n",
    "im = Image.open(fname)\n",
    "n,t= predictimg(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_figs([t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoStream:\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        self.stream.open('http://192.75.244.23:4747/video')\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while True:\n",
    "            if self.stopped:\n",
    "                return\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def read(self):\n",
    "        # Return the latest frame\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "score = 0\n",
    "pred = 0\n",
    "last = 0\n",
    "human_string = None\n",
    "vs = VideoStream(src=1).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \"NONE\"\n",
    "l=0\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame_count += 1\n",
    "    cv2.putText(frame, \"*\", (160, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (160, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    #frame = frame[40:160,40:160] #y1y2x1x2\n",
    "    if frame_count % 15 == 0:\n",
    "        img = frame[110:410,160:460] #y1y2x1x2\n",
    "        img = img[..., ::-1]\n",
    "        img = cv2.resize(img, (32, 32))\n",
    "        inp = Variable(torch.from_numpy(preprocess(img)).float().unsqueeze(0)) #\n",
    "        out = model(inp) #\n",
    "        prob = softmax(out.data.numpy()[0])\n",
    "        n = cifar10_class_names[np.argmax(prob)]\n",
    "        #l = int(len(n)/2)\n",
    "                           \n",
    "    cv2.putText(frame, n, (280, 430),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "vs.stop()   \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \"NONE\"\n",
    "pilTrans = transforms.ToPILImage()\n",
    "tnsr = transforms.ToTensor()\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame_count +=1\n",
    "    cv2.putText(frame, \"*\", (160, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (160, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    if frame_count % 200 == 0:\n",
    "        img = frame[110:410,160:460]\n",
    "        img = img[..., ::-1]\n",
    "        img = cv2.resize(img,(32,32))\n",
    "        im = pilTrans(torch.from_numpy(preprocess(img)))\n",
    "        im = transforms.functional.hflip(im)\n",
    "        inp = Variable(tnsr(im)).float().unsqueeze(0)\n",
    "        out = model(inp)\n",
    "        prob = softmax(out.data.numpy()[0])\n",
    "        n = cifar10_class_names[np.argmax(prob)]\n",
    "    cv2.putText(frame, n, (280, 430),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "vs.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(4/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
