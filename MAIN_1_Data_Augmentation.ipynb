{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from models.enhanced_resnet import EnhancedResnet\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import torch\n",
    "import cv2\n",
    "from scipy.optimize import differential_evolution\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from model import BasicCNN\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import random\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figs(imgs):\n",
    "    f = plt.figure(figsize=(8,4))\n",
    "    plt.axis('off')\n",
    "    tot = len(imgs)\n",
    "    i=0\n",
    "    pilTrans = transforms.ToPILImage()\n",
    "    for img in imgs:\n",
    "        i = i+1\n",
    "        f.add_subplot(1,tot, i)\n",
    "        plt.imshow(pilTrans(img))\n",
    "    plt.show()\n",
    "def preprocess(img):\n",
    "    img = img.astype(np.float32)\n",
    "    img /= 255.0\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    return img\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "def scale(x, scale=5):\n",
    "    return cv2.resize(x, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "def perturb(x):\n",
    "    adv_img = img.copy()\n",
    "    pixs = np.array(np.split(x, len(x)/5)).astype(int)\n",
    "    loc = (pixs[:, 0], pixs[:,1])\n",
    "    val = pixs[:, 2:]\n",
    "    adv_img[loc] = val\n",
    "    return adv_img\n",
    "def optimize(x):\n",
    "    adv_img = perturb(x)\n",
    "    inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    return prob[pred_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "tr = datasets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "pred_adv = 0\n",
    "prob_adv = 0\n",
    "def callback(x, convergence):\n",
    "    global pred_adv, prob_adv\n",
    "    adv_img = perturb(x)\n",
    "    inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    pred_adv = np.argmax(prob)\n",
    "    prob_adv = prob[pred_adv]\n",
    "    if pred_adv != pred_orig and prob_adv >= 0.9:\n",
    "        print('Attack successful..')\n",
    "        print('Prob [%s]: %f' %(cifar10_class_names[pred_adv], prob_adv))\n",
    "        print()\n",
    "        return True\n",
    "    else:\n",
    "        print('Prob [%s]: %f' %(cifar10_class_names[pred_orig], prob[pred_orig]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 318\n",
    "fname = \"images/adv_img_\"+str(idx)+\".png\"\n",
    "d = 1\n",
    "iters = 600\n",
    "popsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnsr,lb = tr.__getitem__(idx)\n",
    "save_image(tnsr,\"images/testing.png\")\n",
    "image_path = \"images/testing.png\" #images/airplane.png or car.png adv-3.png adv-37.png adv-158.png 221.png\n",
    "cifar10_class_names = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before attack: dog\n",
      "Probability: 0.896191\n"
     ]
    }
   ],
   "source": [
    "orig = cv2.imread(image_path)[..., ::-1]\n",
    "orig = cv2.resize(orig, (32, 32))\n",
    "img = orig.copy()\n",
    "shape = orig.shape\n",
    "model = BasicCNN()\n",
    "saved = torch.load(\"saved/cifar10_basiccnn.pth.tar\")\n",
    "model.load_state_dict(saved['state_dict'])\n",
    "model.eval()\n",
    "inp = Variable(torch.from_numpy(preprocess(img)).float().unsqueeze(0))\n",
    "prob_orig = softmax(model(inp).data.numpy()[0])\n",
    "pred_orig = np.argmax(prob_orig)\n",
    "print('Prediction before attack: %s' %(cifar10_class_names[pred_orig]))\n",
    "print('Probability: %f' %(prob_orig[pred_orig]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictimg(img):\n",
    "    tnsr = transforms.ToTensor()\n",
    "    i = random.randint(1,3)\n",
    "    if i==1:\n",
    "        print(\"Vertical transformation applied.\")\n",
    "        img = transforms.functional.vflip(img)\n",
    "    elif i==2:\n",
    "        print(\"Horizontal flip applied.\")\n",
    "        img = transforms.functional.hflip(img)\n",
    "    else:\n",
    "        ang = {1:30,2:45,3:60,4:120,5:135,6:225}\n",
    "        j = random.randint(1,6)\n",
    "        print(\"Imgae rotation with %d degrees applied.\"%(ang[j]))\n",
    "        img = transforms.functional.rotate(img,angle=ang[j]) \n",
    "    t = tnsr(img)\n",
    "    inp = Variable(t).float().unsqueeze(0)\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    n = cifar10_class_names[np.argmax(prob)]\n",
    "    v = np.amax(prob)\n",
    "    print('Prediction of the image after attack: %s' %(n))\n",
    "    print('Confidence: %f' %(v))\n",
    "    return n,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictimglive(img):\n",
    "    #tnsr = transforms.ToTensor()\n",
    "    i = random.randint(1,3)\n",
    "    if i==1:\n",
    "        print(\"Vertical Applied:\")\n",
    "        img = transforms.functional.vflip(img)\n",
    "    elif i==2:\n",
    "        print(\"Horizontal flip applied:\")\n",
    "        img = transforms.functional.hflip(img)\n",
    "    else:\n",
    "        ang = {1:30,2:45,3:60,4:120,5:135,6:225}\n",
    "        j = random.randint(1,6)\n",
    "        print(\"Imgae rotation with %d degrees applied:\"%(ang[j]))\n",
    "        img = transforms.functional.rotate(img,angle=ang[j]) \n",
    "    #t = tnsr(img)\n",
    "    inp = Variable(img).float().unsqueeze(0)\n",
    "    out = model(inp)\n",
    "    prob = softmax(out.data.numpy()[0])\n",
    "    n = cifar10_class_names[np.argmax(prob)]\n",
    "    #v = np.amax(prob)\n",
    "    #print('Prediction of the image after attack: %s' %(n))\n",
    "    #print('Confidence: %f' %(v))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob [dog]: 0.643075\n",
      "Prob [dog]: 0.643075\n",
      "Prob [dog]: 0.643075\n",
      "Prob [dog]: 0.643075\n",
      "Prob [dog]: 0.643075\n",
      "Prob [dog]: 0.633599\n",
      "Prob [dog]: 0.633599\n",
      "Prob [dog]: 0.509659\n",
      "Prob [dog]: 0.489746\n",
      "Prob [dog]: 0.474802\n",
      "Prob [dog]: 0.474802\n",
      "Prob [dog]: 0.453764\n",
      "Prob [dog]: 0.453764\n",
      "Prob [dog]: 0.453764\n",
      "Prob [dog]: 0.449816\n",
      "Prob [dog]: 0.449816\n",
      "Prob [dog]: 0.449816\n",
      "Prob [dog]: 0.449816\n",
      "Prob [dog]: 0.449816\n",
      "Prob [dog]: 0.444786\n",
      "Prob [dog]: 0.444786\n",
      "Prob [dog]: 0.444786\n",
      "Prob [dog]: 0.444786\n",
      "Prob [dog]: 0.444486\n",
      "Prob [dog]: 0.444486\n",
      "Prob [dog]: 0.443094\n",
      "Prob [dog]: 0.442851\n",
      "Prob [dog]: 0.442851\n",
      "Prob [dog]: 0.442355\n",
      "Prob [dog]: 0.442355\n",
      "Prob [dog]: 0.442355\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.441781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentialevolution.py:603: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence=self.tol / convergence) is True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob [dog]: 0.441781\n",
      "Prob [dog]: 0.896191 --> Prob[frog]: 0.451300\n"
     ]
    }
   ],
   "source": [
    "bounds = [(0, shape[0]-1), (0, shape[1]), (0, 255), (0, 255), (0, 255)] * d\n",
    "result = differential_evolution(optimize, bounds, maxiter=iters, popsize=popsize, tol=1e-5, callback=callback)\n",
    "adv_img = perturb(result.x)\n",
    "inp = Variable(torch.from_numpy(preprocess(adv_img)).float().unsqueeze(0))\n",
    "out = model(inp)\n",
    "prob = softmax(out.data.numpy()[0])\n",
    "print('Prob [%s]: %f --> Prob[%s]: %f' %(cifar10_class_names[pred_orig], prob_orig[pred_orig], cifar10_class_names[pred_adv], prob_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(fname, adv_img[..., ::-1]) #images/adv_img_airplane.png\n",
    "cv2.imshow('adversarial image', scale(adv_img[..., ::-1]))\n",
    "while True:\n",
    "    key = cv2.waitKey(33)\n",
    "    if key == 27 or key == 32:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of adevrserial image with random data augmentation:\n",
      "Prediction before attack: dog\n",
      "Probability: 0.896191\n",
      "Horizontal flip applied.\n",
      "Prediction of the image after attack: frog\n",
      "Confidence: 0.590027\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction of adevrserial image with random data augmentation:\")\n",
    "print('Prediction before attack: %s' %(cifar10_class_names[pred_orig]))\n",
    "print('Probability: %f' %(prob_orig[pred_orig]))\n",
    "im = Image.open(fname)\n",
    "n,t= predictimg(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_figs([t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoStream:\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        self.stream.open('http://192.168.0.33:4747/video')\n",
    "        (self.grabbed, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while True:\n",
    "            if self.stopped:\n",
    "                return\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def read(self):\n",
    "        # Return the latest frame\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "score = 0\n",
    "pred = 0\n",
    "last = 0\n",
    "human_string = None\n",
    "vs = VideoStream(src=1).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \"NONE\"\n",
    "l=0\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame_count += 1\n",
    "    cv2.putText(frame, \"*\", (160, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (160, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    #frame = frame[40:160,40:160] #y1y2x1x2\n",
    "    if frame_count % 15 == 0:\n",
    "        img = frame[110:410,160:460] #y1y2x1x2\n",
    "        img = img[..., ::-1]\n",
    "        img = cv2.resize(img, (32, 32))\n",
    "        inp = Variable(torch.from_numpy(preprocess(img)).float().unsqueeze(0)) #\n",
    "        out = model(inp) #\n",
    "        prob = softmax(out.data.numpy()[0])\n",
    "        n = cifar10_class_names[np.argmax(prob)]\n",
    "        #l = int(len(n)/2)\n",
    "                           \n",
    "    cv2.putText(frame, n, (280, 430),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "vs.stop()   \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \"NONE\"\n",
    "pilTrans = transforms.ToPILImage()\n",
    "tnsr = transforms.ToTensor()\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame_count +=1\n",
    "    cv2.putText(frame, \"*\", (160, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (160, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 110),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.putText(frame, \"*\", (460, 410),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    if frame_count % 200 == 0:\n",
    "        img = frame[110:410,160:460]\n",
    "        img = img[..., ::-1]\n",
    "        img = cv2.resize(img,(32,32))\n",
    "        im = pilTrans(torch.from_numpy(preprocess(img)))\n",
    "        im = transforms.functional.hflip(im)\n",
    "        inp = Variable(tnsr(im)).float().unsqueeze(0)\n",
    "        out = model(inp)\n",
    "        prob = softmax(out.data.numpy()[0])\n",
    "        n = cifar10_class_names[np.argmax(prob)]\n",
    "    cv2.putText(frame, n, (280, 430),cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 255))\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "vs.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(4/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
